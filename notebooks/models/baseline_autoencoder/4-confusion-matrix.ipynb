{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from src import MODELS_DIR, MLFLOW_TRACKING_URI, DATA_PATH\n",
    "from src.data import TrainValTestSplitter, MURASubset\n",
    "from src.data.transforms import *\n",
    "from src.features.augmentation import Augmentation\n",
    "from src.models.autoencoders import BottleneckAutoencoder, BaselineAutoencoder\n",
    "from src.models.gans import DCGAN\n",
    "from src.models.vaetorch import VAE\n",
    "from src.models import BaselineAutoencoder\n",
    "from src.features.pixelwise_loss import PixelwiseLoss\n",
    "from src.models.autoencoders import MaskedMSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best masked model\n",
    "\n",
    "### Initilize and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Train subset=================\n",
      "Size: 3012\n",
      "Percentage from original data: 0.5145199863341305\n",
      "Percentage of negatives: 1.0\n",
      "Number of patients: 1017\n",
      "=============Validation subset===============\n",
      "Size: 1419\n",
      "Percentage from original data: 0.2423983600956611\n",
      "Percentage of negatives: 0.485553206483439\n",
      "Number of patients: 473\n",
      "=================Test subset=================\n",
      "Size: 1423\n",
      "Percentage from original data: 0.24308165357020842\n",
      "Percentage of negatives: 0.4195361911454673\n",
      "Number of patients: 474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaselineAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (22): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU()\n",
       "    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "    (27): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (16): ReLU()\n",
       "    (17): Tanh()\n",
       "  )\n",
       "  (inner_loss): MaskedMSELoss(\n",
       "    (criterion): MSELoss()\n",
       "  )\n",
       "  (outer_loss): MaskedMSELoss(\n",
       "    (criterion): MSELoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to mlflow\n",
    "client = mlflow.tracking.MlflowClient(MLFLOW_TRACKING_URI)\n",
    "client.list_experiments()\n",
    "# get the path of the saved model from mlflow\n",
    "run_id = '5ca7f67c33674926a00590752c877fe5'\n",
    "experiment = client.get_experiment('1')\n",
    "path = f'{experiment.artifact_location}/{run_id}/artifacts/BaselineAutoencoder.pth'\n",
    "path\n",
    "\n",
    "num_workers = 7\n",
    "log_to_mlflow = False\n",
    "device = \"cuda\"\n",
    "\n",
    "# Mlflow parameters\n",
    "run_params = {\n",
    "    'batch_size': 32,\n",
    "    'image_resolution': (512, 512),\n",
    "    'num_epochs': 1000,\n",
    "    'batch_normalisation': True,\n",
    "    'pipeline': {\n",
    "        'hist_equalisation': True,\n",
    "        'data_source': 'XR_HAND_PHOTOSHOP',\n",
    "    },\n",
    "    'masked_loss_on_val': True,\n",
    "    'masked_loss_on_train': True,\n",
    "    'soft_labels': True,\n",
    "    'glr': 0.001,\n",
    "    'dlr': 0.00005,\n",
    "    'z_dim': 1000,\n",
    "    'lr': 0.0001\n",
    "}\n",
    "\n",
    "\n",
    "# Preprocessing pipeline\n",
    "\n",
    "composed_transforms_val = Compose([GrayScale(),\n",
    "                                   HistEqualisation(active=run_params['pipeline']['hist_equalisation']),\n",
    "                                   Resize(run_params['image_resolution'], keep_aspect_ratio=True),\n",
    "                                   Augmentation(iaa.Sequential([iaa.PadToFixedSize(512, 512, position='center')])),\n",
    "                                   # Padding(max_shape=run_params['image_resolution']),\n",
    "                                   # max_shape - max size of image after augmentation\n",
    "                                   MinMaxNormalization(),\n",
    "                                   ToTensor()])\n",
    "\n",
    "# get data\n",
    "\n",
    "data_path = f'{DATA_PATH}/{run_params[\"pipeline\"][\"data_source\"]}'\n",
    "splitter = TrainValTestSplitter(path_to_data=data_path)\n",
    "\n",
    "test = MURASubset(filenames=splitter.data_test.path, true_labels=splitter.data_test.label,\n",
    "                  patients=splitter.data_test.patient, transform=composed_transforms_val)\n",
    "\n",
    "validation = MURASubset(filenames=splitter.data_val.path, true_labels=splitter.data_val.label,\n",
    "                        patients=splitter.data_val.patient, transform=composed_transforms_val)\n",
    "\n",
    "val_loader = DataLoader(validation, batch_size=run_params['batch_size'], shuffle=True, num_workers=num_workers)\n",
    "\n",
    "test_loader = DataLoader(test, batch_size=run_params['batch_size'], shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# get model (change path to path to a trained model\n",
    "\n",
    "model = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "# set loss function\n",
    "\n",
    "outer_loss = MaskedMSELoss(reduction='none')\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get optimal threshold based on F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 45/45 [00:08<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC on validation: 0.5637970455494363\n",
      "MSE on validation: 0.0010469848057255149\n",
      "F1-score on validation: 0.6793857608189856. Optimal threshold on validation: 0.00020105995645280927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mode\n",
    "val_metrics = model.evaluate(val_loader, 'validation', log_to_mlflow=log_to_mlflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "type: 100%|██████████| 45/45 [00:08<00:00,  5.18it/s]\n"
     ]
    }
   ],
   "source": [
    "masked_loss_on_val = True\n",
    "# Evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = []\n",
    "    true_labels = []\n",
    "    for batch_data in tqdm(test_loader, desc='type', total=len(test_loader)):\n",
    "        # Format input batch\n",
    "        inp = batch_data['image'].to(device)\n",
    "        mask = batch_data['mask'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(inp)\n",
    "        loss = outer_loss(output, inp, mask) if masked_loss_on_val else outer_loss(output, inp)\n",
    "\n",
    "        # Scores, based on MSE - higher MSE correspond to abnormal image\n",
    "        if masked_loss_on_val:\n",
    "            sum_loss = loss.to('cpu').numpy().sum(axis=(1, 2, 3))\n",
    "            sum_mask = mask.to('cpu').numpy().sum(axis=(1, 2, 3))\n",
    "            score = sum_loss / sum_mask\n",
    "        else:\n",
    "            score = loss.to('cpu').numpy().mean(axis=(1, 2, 3))\n",
    "\n",
    "        scores.extend(score)\n",
    "        true_labels.extend(batch_data['label'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Confusion matrix based on optimal mse thresholds prediction. Almost all images are predicted as positive. This results in a good F1 score but doesn't make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 594, 0, 826)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc prediction based on optimal threshold\n",
    "opt_threshold = val_metrics['optimal mse threshold']\n",
    "pred_list = [1 if x > opt_threshold else 0 for x in scores]\n",
    "tn, fp, fn, tp = confusion_matrix(true_labels, pred_list).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
